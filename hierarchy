# TRAINING LOOP

## PASSED_OBJECTS
DATA_DICTIONARY = {'paths':['metadata', .. , ]} ## dictionary, 'paths' : ['metadata', .. ,]

## MAGIC NUMBERS
NUMBER_EPOCHS = 100 (default: TBD, or passed by user)
MODEL_TYPE = 'GPT-2' 
LEARNING_RATE = 6e-4 
DEVICE = 'cuda'
TRAIN_VAL_TEST_SPLIT = [0.7, 0.2, 0.1]
MODEL_PARAMETERS = {'param':float, .. ,} ## dictionary of parameters, has callable defaults based on MODEL_TYPE


...

## CREATED_OBJECTS
current_model = engine.get_model(MODEL_TYPE, MODEL_PARAMETERS)
dataset = engine.get_dataset(DATA_DICTIONARY) ## dictionary, 'paths' (csv) : 'number of indices' (frames)
best_model = current_model

losses = []

train_dataset, validate_dataset, test_dataset = engine.get_dataset_split(dataset, TRAIN_VAL_TEST_SPLIT, MODEL_PARAMETERS['block_size'])

for() -> per epoch
    batches = get_batches(train_dataset, MODEL_PARAMETERS['block_size']) ### a lookup table
    for() -> per batch per epoch
        ## learning on the train_dataset

    ## validate on the validation dataset
    loss_validation = engine.get_loss(current_model, validate_dataset)

    if current_model_loss < best_model_loss:
        best_model = current_model

## test best_model on test_dataset
loss_test = engine.get_loss(best_model, test_dataset)
    
    